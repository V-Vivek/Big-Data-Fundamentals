# Data Integration
- Data integration is the process of combining data from multiple sources into a single, unified view. 
- The process of data integration includes a number of different steps, including
  ## Data Extraction
    - To extract data from one or more sources. This can include databases, flat files, or other systems.
    - The extracted data is usually stored in a staging area for further processing

  ## Data Transformation
    - It involves cleaning, validating, and transforming the data so that it is ready for loading into the destination system.
    - The transformation step can include tasks such as removing duplicates, converting data types, or calculating new values.

  ## Data Loading
    - To load the transformed data into the destination system. 
    - This can include a data warehouse, a data lake, or another system. 
    - The loaded data is then typically available for reporting, analysis, and other business processes.

  ## Data Quality Management
    - This step involves monitoring, identifying and correcting errors and inconsistencies in data
    - To ensure that the data is accurate and reliable.
  
  ## Data Governance
    - To ensure that the data is properly managed and protected throughout the data integration process
    - And ensures that data is being used in compliance with regulatory and legal requirements.

# Extract Transform Load (ETL)
<img src='https://panoply.io/uploads/versions/diagram4---x----750-328x---.jpg'>



# Etract Load Transform (ELT)
<img src='https://miro.medium.com/max/640/1*UAbW9DFAtSOqnz9-Mt2RSA.webp'>

# Types of DataBase Management System (DBMS)
- 
    ## OLTP (Online Transaction Processing)
    - Designed to handle a large number of short transactions, such as inserting, updating, and deleting data. 
    - Typically used in operational environments, such as retail stores, banks and e-commerce websites. 
    - Optimized for fast data retrieval and data manipulation, and they typically use a ***normalized data model**** to minimize data redundancy.

-
  ## OLAP (Online Analytical Processing)
    - Designed for analytical and reporting purposes.
    - Used to analyze large amounts of historical data and provide insights into the data. 
    - Optimized for fast query performance and are typically built on top of a ***data warehouse or data mart***. 
    - Uses a ***denormalized data model***, which allows for faster query performance at the cost of increased data redundancy.

- In short, OLTP systems are focused on managing and processing transactions, while OLAP systems are focused on providing fast and flexible access to data for analytical and reporting purposes. 
- The two systems are often used in conjunction to support business operations, with OLTP systems capturing and managing transactional data and OLAP systems providing analytical capabilities on that data.




